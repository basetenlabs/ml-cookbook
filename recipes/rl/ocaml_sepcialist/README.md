# OCaml Specialist 

The recipe here provides a way to train a model code OCaml. The reward function is simple: it returns a 1 for code that compiles, and a 0 for code that doesn't. While 
this won't produce the most prolific OCaml coder, it serves to demonstrate the power and fleixbility of Baseten's training platform, allowing you to instrument
environments with nontrivial dependencies. 

## Training Configuration Details 

The configuration has special properties that lead to better rewards in the training run:
* Both runs implement (Truncated Importance Sampling)[https://fengyao.notion.site/off-policy-rl]
* The LoRA run is a faithful adaptation of Lora-without-regret using VeRL, specifically with rank = 8. Existing dependencies don't allow for rank = 1.


## Examples 

Below is a comparison of the base model and finetuned model, generated by (api_eval.py)[./qwen3-8b-lora-verl]
```
==== Prompt ====
(**Write a function to check if a string is present as a substring in a given list of string values.
*)
let find_substring (str1 : string list) (sub_str : string) : bool =

==== Base Model ====
Solution: 
let find_substring (str1 : string list) (sub_str : string) : bool =
  List.exists (fun s -> String.contains s sub_str) str1

Compiles: False

==== Finetuned LoRA ====
Solution: 
let find_substring (str1 : string list) (sub_str : string) : bool =
  let len_sub = String.length sub_str in
  List.exists (fun s ->
    let len_s = String.length s in
    if len_sub > len_s then false
    else
      let rec loop i =
        if i > len_s - len_sub then false
        else if String.sub s i len_sub = sub_str then true
        else loop (i + 1)
      in
      loop 0
  ) str1

Compiles: True
````

## Scaling

To scale this to a Qwen 30b, use
* 4 nodes for the full finetune
* LoRA: <TODO>
